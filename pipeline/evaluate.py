"""
Script ƒë√°nh gi√° model detection (YOLO) tr√™n t·∫≠p validation/test.

T√≠nh to√°n c√°c metrics: mAP, precision, recall, F1-score cho t·ª´ng class v√† overall.
C√≥ th·ªÉ xu·∫•t k·∫øt qu·∫£ visualization (v·∫Ω c·∫£ bbox d·ª± ƒëo√°n v√† bbox th·ª±c t·∫ø tr√™n c√πng ·∫£nh).

C√°ch s·ª≠ d·ª•ng:
  # ƒê√°nh gi√° tr√™n validation set
  python pipeline/evaluate.py --weights processed/det/runs/yolov8n/weights/best.pt --split val

  # ƒê√°nh gi√° tr√™n test set
  python pipeline/evaluate.py --weights processed/det/runs/yolov8n/weights/best.pt --split test

  # ƒê√°nh gi√° v·ªõi visualization (v·∫Ω c·∫£ GT v√† predicted boxes)
  python pipeline/evaluate.py --weights processed/det/runs/yolov8n/weights/best.pt --split val --save_vis --vis_dir results/vis

  # ƒê√°nh gi√° v·ªõi confidence threshold t√πy ch·ªânh
  python pipeline/evaluate.py --weights processed/det/runs/yolov8n/weights/best.pt --conf 0.25 --iou 0.45

  # Visualization v·ªõi ch·ªâ ƒë·ªãnh label directory
  python pipeline/evaluate.py --weights processed/det/runs/yolov8n/weights/best.pt --split val --save_vis --label_dir processed/knee/labels

L∆∞u √Ω v·ªÅ visualization:
  - GT boxes: m√†u xanh l√° (green)
  - Predicted boxes: m√†u ƒë·ªè (red) v·ªõi confidence score
  - T·ª± ƒë·ªông t√¨m th∆∞ m·ª•c labels t·ª´ img_dir, ho·∫∑c d√πng --label_dir ƒë·ªÉ ch·ªâ ƒë·ªãnh
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import numpy as np
import cv2

ROOT_DIR = os.path.dirname(os.path.dirname(__file__))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

from config import CLASSES
from pipeline.utils.split_utils import read_split_stems, extract_orig_stem_from_crop_path
from pipeline.model_det import build_detection_model


def list_images(img_dir: str) -> List[str]:
    """Li·ªát k√™ c√°c file ·∫£nh trong th∆∞ m·ª•c theo c√°c ƒëu√¥i ph·ªï bi·∫øn, ƒë√£ sort."""
    exts = {".jpg", ".jpeg", ".png", ".bmp"}
    files = [f for f in os.listdir(img_dir) if os.path.splitext(f)[1].lower() in exts]
    files.sort()
    return files


def make_dataset_files_for_eval(
    img_dir: str, splits_dir: str, split: str, out_dir: str
) -> str:
    """
    T·∫°o file dataset YOLO cho evaluation (t∆∞∆°ng t·ª± train_det.py nh∆∞ng ch·ªâ cho m·ªôt split).
    
    Args:
        img_dir: Th∆∞ m·ª•c ch·ª©a ·∫£nh crops
        splits_dir: Th∆∞ m·ª•c ch·ª©a file splits
        split: T√™n split ('val' ho·∫∑c 'test')
        out_dir: Th∆∞ m·ª•c output
    
    Returns:
        ƒê∆∞·ªùng d·∫´n ƒë·∫øn file dataset.yaml
    """
    os.makedirs(out_dir, exist_ok=True)
    imgs = list_images(img_dir)
    if not imgs:
        raise SystemExit(f"No images found in {img_dir}")

    split_list = os.path.join(splits_dir, f"{split}.txt")
    if not os.path.exists(split_list):
        raise SystemExit(f"Missing {split_list}")

    split_stems = read_split_stems(split_list)
    print(f"Loaded {split} split: {len(split_stems)} stems")
    if len(split_stems) > 0:
        print(f"  Example stems: {list(split_stems)[:3]}")

    # X√¢y alias base-stem: lo·∫°i b·ªè h·∫≠u t·ªë _<digits> ƒë·ªÉ linh ho·∫°t khi map crop -> g·ªëc
    def base_stem(s: str) -> str:
        if "_" in s and s.rsplit("_", 1)[-1].isdigit():
            return s.rsplit("_", 1)[0]
        return s
    split_base = {base_stem(s) for s in split_stems}

    abs_img_dir = os.path.abspath(img_dir)
    split_paths: List[str] = []
    unmatched_stems = set()

    for f in imgs:
        p = os.path.join(abs_img_dir, f)
        orig_stem = extract_orig_stem_from_crop_path(p)
        if orig_stem in split_stems or base_stem(orig_stem) in split_base:
            split_paths.append(p.replace("\\", "/"))
        else:
            unmatched_stems.add(orig_stem)

    print(f"Found {len(imgs)} images total")
    print(f"Mapped to {split}: {len(split_paths)} images")
    if unmatched_stems and len(unmatched_stems) <= 10:
        print(f"  Unmatched stems (first 10): {list(unmatched_stems)[:10]}")
    elif unmatched_stems:
        print(f"  Unmatched stems count: {len(unmatched_stems)}")

    if not split_paths:
        raise SystemExit(f"No images mapped to {split} split. Check stems and crop naming.")

    split_txt = os.path.join(out_dir, f"{split}.txt")
    with open(split_txt, "w", encoding="utf-8") as f:
        f.write("\n".join(split_paths))

    names = [CLASSES[i] for i in sorted(CLASSES.keys())]
    yaml_path = os.path.join(out_dir, f"dataset_{split}.yaml")
    split_txt_posix = os.path.abspath(split_txt).replace("\\", "/")
    
    # C·∫ßn t·∫°o m·ªôt file dataset.yaml t·∫°m th·ªùi v·ªõi train v√† val gi·ªëng nhau (ho·∫∑c ch·ªâ val)
    # Ultralytics y√™u c·∫ßu c·∫£ train v√† val trong yaml, nh∆∞ng ta c√≥ th·ªÉ d√πng c√πng file
    with open(yaml_path, "w", encoding="utf-8") as f:
        f.write("names: \n")
        for i, n in enumerate(names):
            f.write(f"  {i}: {n}\n")
        f.write(f"nc: {len(names)}\n")
        f.write(f"train: {split_txt_posix}\n")
        f.write(f"val: {split_txt_posix}\n")

    return yaml_path


def parse_args():
    """Parse tham s·ªë d√≤ng l·ªánh cho evaluation."""
    p = argparse.ArgumentParser(description="Evaluate YOLO detector on validation/test set")
    p.add_argument(
        "--weights",
        required=True,
        help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn file weights ƒë√£ train (vd: processed/det/runs/yolov8n/weights/best.pt)"
    )
    p.add_argument(
        "--img_dir",
        default=os.path.join("processed", "knee", "images"),
        help="Th∆∞ m·ª•c ch·ª©a ·∫£nh crops"
    )
    p.add_argument(
        "--splits_dir",
        default="splits",
        help="Th∆∞ m·ª•c ch·ª©a file splits"
    )
    p.add_argument(
        "--split",
        default="val",
        choices=["val", "test"],
        help="Split ƒë·ªÉ ƒë√°nh gi√° (val ho·∫∑c test)"
    )
    p.add_argument(
        "--out_dir",
        default=os.path.join("processed", "det", "eval"),
        help="Th∆∞ m·ª•c output cho k·∫øt qu·∫£ evaluation"
    )
    p.add_argument(
        "--conf",
        type=float,
        default=0.25,
        help="Confidence threshold cho detection (m·∫∑c ƒë·ªãnh: 0.25)"
    )
    p.add_argument(
        "--iou",
        type=float,
        default=0.45,
        help="IoU threshold cho NMS (m·∫∑c ƒë·ªãnh: 0.45)"
    )
    p.add_argument(
        "--imgsz",
        type=int,
        default=640,
        help="K√≠ch th∆∞·ªõc ·∫£nh input (m·∫∑c ƒë·ªãnh: 640)"
    )
    p.add_argument(
        "--device",
        type=str,
        default=None,
        help="Device ƒë·ªÉ ch·∫°y (cuda, cpu, ho·∫∑c cuda:0). N·∫øu kh√¥ng ch·ªâ ƒë·ªãnh, t·ª± ƒë·ªông ch·ªçn."
    )
    p.add_argument(
        "--save_vis",
        action="store_true",
        help="L∆∞u visualization (v·∫Ω bbox d·ª± ƒëo√°n tr√™n ·∫£nh)"
    )
    p.add_argument(
        "--vis_dir",
        default=None,
        help="Th∆∞ m·ª•c l∆∞u visualization (m·∫∑c ƒë·ªãnh: {out_dir}/visualizations)"
    )
    p.add_argument(
        "--vis_n",
        type=int,
        default=50,
        help="S·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ visualize (m·∫∑c ƒë·ªãnh: 50, -1 ƒë·ªÉ visualize t·∫•t c·∫£)"
    )
    p.add_argument(
        "--save_json",
        action="store_true",
        help="L∆∞u k·∫øt qu·∫£ metrics d∆∞·ªõi d·∫°ng JSON"
    )
    p.add_argument(
        "--backend",
        default=None,
        help="Backend detector (m·∫∑c ƒë·ªãnh: ultralytics)"
    )
    p.add_argument(
        "--label_dir",
        default=None,
        help="Th∆∞ m·ª•c ch·ª©a labels GT (m·∫∑c ƒë·ªãnh: t·ª± ƒë·ªông t√¨m t·ª´ img_dir)"
    )
    return p.parse_args()


def read_yolo_label(label_path: str) -> List[Tuple[int, float, float, float, float]]:
    """
    ƒê·ªçc file label YOLO format.
    
    Returns:
        List of (class_id, x_center, y_center, width, height) - normalized coordinates
    """
    boxes = []
    if not os.path.exists(label_path):
        return boxes
    
    try:
        with open(label_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = line.split()
                if len(parts) != 5:
                    continue
                try:
                    cls_id = int(float(parts[0]))
                    x, y, w, h = map(float, parts[1:5])
                    # Validate normalized coordinates
                    if 0.0 <= x <= 1.0 and 0.0 <= y <= 1.0 and 0.0 < w <= 1.0 and 0.0 < h <= 1.0:
                        boxes.append((cls_id, x, y, w, h))
                except (ValueError, IndexError):
                    continue
    except Exception as e:
        print(f"  ‚ö†Ô∏è  L·ªói ƒë·ªçc label {label_path}: {e}")
    
    return boxes


def draw_yolo_box(
    img: np.ndarray,
    cls_id: int,
    x: float,
    y: float,
    w: float,
    h: float,
    color: Tuple[int, int, int] = (255, 0, 0),
    thickness: int = 2,
    font_scale: float = 0.6,
    label_prefix: str = "",
    show_conf: bool = False,
    conf: float = 0.0,
) -> None:
    """
    V·∫Ω bounding box YOLO format (normalized coordinates) l√™n ·∫£nh.
    
    Args:
        img: ·∫¢nh numpy array (BGR format)
        cls_id: Class ID
        x, y, w, h: Normalized coordinates (center_x, center_y, width, height)
        color: M√†u BGR
        thickness: ƒê·ªô d√†y ƒë∆∞·ªùng vi·ªÅn
        font_scale: K√≠ch th∆∞·ªõc font
        label_prefix: Ti·ªÅn t·ªë cho label (vd: "GT" ho·∫∑c "Pred")
        show_conf: C√≥ hi·ªÉn th·ªã confidence kh√¥ng
        conf: Confidence score
    """
    H, W = img.shape[:2]
    cx, cy = x * W, y * H
    bw, bh = w * W, h * H
    x1 = int(round(cx - bw / 2))
    y1 = int(round(cy - bh / 2))
    x2 = int(round(cx + bw / 2))
    y2 = int(round(cy + bh / 2))
    
    # Clamp to image boundaries
    x1 = max(0, min(W - 1, x1))
    y1 = max(0, min(H - 1, y1))
    x2 = max(0, min(W - 1, x2))
    y2 = max(0, min(H - 1, y2))
    
    if x2 <= x1 or y2 <= y1:
        return
    
    # V·∫Ω rectangle
    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)
    
    # T·∫°o label text
    class_name = CLASSES.get(cls_id, f"Class{cls_id}")
    if label_prefix:
        label = f"{label_prefix}: {class_name}"
    else:
        label = class_name
    
    if show_conf and conf > 0:
        label += f" {conf:.2f}"
    
    # V·∫Ω label background v√† text
    (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 1)
    cv2.rectangle(img, (x1, y1 - th - 4), (x1 + tw + 4, y1), color, -1)
    cv2.putText(
        img, label, (x1 + 2, y1 - 2),
        cv2.FONT_HERSHEY_SIMPLEX, font_scale,
        (255, 255, 255), 1, cv2.LINE_AA
    )


def visualize_predictions_with_gt(
    img_path: str,
    label_path: str,
    detector,
    conf_threshold: float,
    iou_threshold: float,
    imgsz: int,
    device: str,
    out_path: str,
) -> bool:
    """
    V·∫Ω c·∫£ GT boxes v√† predicted boxes l√™n c√πng m·ªôt ·∫£nh.
    
    Args:
        img_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
        label_path: ƒê∆∞·ªùng d·∫´n file label GT
        detector: Model detector
        conf_threshold: Confidence threshold
        iou_threshold: IoU threshold
        imgsz: Image size
        device: Device
        out_path: ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh k·∫øt qu·∫£
    
    Returns:
        True n·∫øu th√†nh c√¥ng, False n·∫øu c√≥ l·ªói
    """
    try:
        # ƒê·ªçc ·∫£nh
        img = cv2.imread(img_path)
        if img is None:
            print(f"  ‚ö†Ô∏è  Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {img_path}")
            return False
        
        # ƒê·ªçc GT boxes
        gt_boxes = read_yolo_label(label_path)
        
        # V·∫Ω GT boxes (m√†u xanh l√°)
        gt_color = (0, 255, 0)  # BGR: xanh l√°
        for cls_id, x, y, w, h in gt_boxes:
            draw_yolo_box(img, cls_id, x, y, w, h, color=gt_color, thickness=2, label_prefix="GT")
        
        # Predict boxes
        pred_results = detector.predict(
            source=img_path,
            conf=conf_threshold,
            iou=iou_threshold,
            imgsz=imgsz,
            device=device,
            verbose=False,
        )
        
        # V·∫Ω predicted boxes (m√†u ƒë·ªè)
        pred_color = (0, 0, 255)  # BGR: ƒë·ªè
        if pred_results and len(pred_results) > 0:
            result = pred_results[0]
            if hasattr(result, 'boxes'):
                boxes = result.boxes
                if boxes is not None and len(boxes) > 0:
                    # L·∫•y th√¥ng tin boxes
                    xyxy = boxes.xyxy.cpu().numpy()  # Absolute coordinates
                    conf = boxes.conf.cpu().numpy()  # Confidence
                    cls = boxes.cls.cpu().numpy().astype(int)  # Class IDs
                    
                    H, W = img.shape[:2]
                    
                    # Convert t·ª´ absolute coordinates sang normalized YOLO format
                    for i in range(len(boxes)):
                        x1, y1, x2, y2 = xyxy[i]
                        # Normalize
                        x_center = ((x1 + x2) / 2) / W
                        y_center = ((y1 + y2) / 2) / H
                        width = (x2 - x1) / W
                        height = (y2 - y1) / H
                        
                        cls_id = int(cls[i])
                        conf_score = float(conf[i])
                        
                        # V·∫Ω predicted box
                        draw_yolo_box(
                            img, cls_id, x_center, y_center, width, height,
                            color=pred_color, thickness=2,
                            label_prefix="Pred", show_conf=True, conf=conf_score
                        )
        
        # L∆∞u ·∫£nh
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        cv2.imwrite(out_path, img)
        return True
        
    except Exception as e:
        print(f"  ‚ö†Ô∏è  L·ªói khi visualize {img_path}: {e}")
        return False


def format_metrics(metrics_dict: Dict) -> str:
    """Format metrics dictionary th√†nh string d·ªÖ ƒë·ªçc."""
    lines = []
    lines.append("\n" + "="*60)
    lines.append("K·∫æT QU·∫¢ ƒê√ÅNH GI√Å")
    lines.append("="*60)
    
    # Overall metrics
    if "metrics/mAP50" in metrics_dict:
        lines.append(f"\nüìä Overall Metrics:")
        lines.append(f"  mAP50:     {metrics_dict.get('metrics/mAP50', 0):.4f}")
        lines.append(f"  mAP50-95:  {metrics_dict.get('metrics/mAP50-95', 0):.4f}")
        lines.append(f"  Precision: {metrics_dict.get('metrics/precision(B)', 0):.4f}")
        lines.append(f"  Recall:    {metrics_dict.get('metrics/recall(B)', 0):.4f}")
        lines.append(f"  F1-score:  {metrics_dict.get('metrics/f1(B)', 0):.4f}")
    
    # Per-class metrics
    names = [CLASSES[i] for i in sorted(CLASSES.keys())]
    if any(f"metrics/{name}/mAP50" in metrics_dict for name in names):
        lines.append(f"\nüìà Per-Class Metrics:")
        for i, name in enumerate(names):
            map50_key = f"metrics/{name}/mAP50"
            map50_95_key = f"metrics/{name}/mAP50-95"
            precision_key = f"metrics/{name}/precision"
            recall_key = f"metrics/{name}/recall"
            
            if map50_key in metrics_dict:
                lines.append(f"\n  {name}:")
                lines.append(f"    mAP50:     {metrics_dict.get(map50_key, 0):.4f}")
                lines.append(f"    mAP50-95:  {metrics_dict.get(map50_95_key, 0):.4f}")
                lines.append(f"    Precision: {metrics_dict.get(precision_key, 0):.4f}")
                lines.append(f"    Recall:    {metrics_dict.get(recall_key, 0):.4f}")
    
    lines.append("\n" + "="*60)
    return "\n".join(lines)


def main():
    args = parse_args()
    
    # Ki·ªÉm tra file weights t·ªìn t·∫°i
    if not os.path.exists(args.weights):
        raise SystemExit(f"Weights file not found: {args.weights}")
    
    # T·ª± ch·ªçn device n·∫øu kh√¥ng ch·ªâ ƒë·ªãnh
    device_arg = args.device
    if not device_arg:
        try:
            import torch
            device_arg = "cuda" if torch.cuda.is_available() else "cpu"
        except Exception:
            device_arg = "cpu"
    
    print(f"\n{'='*60}")
    print(f"ƒê√ÅNH GI√Å MODEL DETECTION")
    print(f"{'='*60}")
    print(f"Weights: {args.weights}")
    print(f"Split: {args.split}")
    print(f"Image directory: {args.img_dir}")
    print(f"Device: {device_arg}")
    print(f"Confidence threshold: {args.conf}")
    print(f"IoU threshold: {args.iou}")
    print(f"Image size: {args.imgsz}")
    print(f"{'='*60}\n")
    
    # ================================================================
    # B∆Ø·ªöC 1 - CHU·∫®N B·ªä D·ªÆ LI·ªÜU
    # ================================================================
    print("üìÅ ƒêang chu·∫©n b·ªã dataset...")
    yaml_path = make_dataset_files_for_eval(
        img_dir=args.img_dir,
        splits_dir=args.splits_dir,
        split=args.split,
        out_dir=args.out_dir
    )
    print(f"Dataset YAML -> {yaml_path}\n")
    
    # ================================================================
    # B∆Ø·ªöC 2 - LOAD MODEL
    # ================================================================
    print("ü§ñ ƒêang load model...")
    detector = build_detection_model(weights=args.weights, backend=args.backend)
    print(f"Model loaded: {args.weights}\n")
    
    # ================================================================
    # B∆Ø·ªöC 3 - EVALUATION
    # ================================================================
    print("üîç ƒêang ƒë√°nh gi√° model...")
    val_kwargs = dict(
        data=yaml_path.replace("\\", "/"),
        conf=args.conf,
        iou=args.iou,
        imgsz=args.imgsz,
        device=device_arg,
        save_json=args.save_json,
        plots=True,  # T·∫°o confusion matrix v√† c√°c plots
    )
    
    # Ch·∫°y validation
    results = detector.val(**val_kwargs)
    
    # ================================================================
    # B∆Ø·ªöC 4 - X·ª¨ L√ù K·∫æT QU·∫¢
    # ================================================================
    print("\n‚úÖ ƒê√°nh gi√° ho√†n t·∫•t!")
    
    # L·∫•y metrics t·ª´ k·∫øt qu·∫£
    metrics_dict = {}
    try:
        if hasattr(results, 'results_dict'):
            metrics_dict = results.results_dict
        elif hasattr(results, 'box'):
            # Ultralytics tr·∫£ v·ªÅ results.box ch·ª©a metrics
            box = results.box
            if hasattr(box, 'map50'):
                metrics_dict['metrics/mAP50'] = float(box.map50)
            if hasattr(box, 'map'):
                metrics_dict['metrics/mAP50-95'] = float(box.map)
            if hasattr(box, 'mp'):
                metrics_dict['metrics/precision(B)'] = float(box.mp)
            if hasattr(box, 'mr'):
                metrics_dict['metrics/recall(B)'] = float(box.mr)
            if hasattr(box, 'f1'):
                metrics_dict['metrics/f1(B)'] = float(box.f1)
            
            # Per-class metrics
            names = [CLASSES[i] for i in sorted(CLASSES.keys())]
            if hasattr(box, 'maps'):
                maps = box.maps  # mAP50-95 per class
                if isinstance(maps, (list, np.ndarray)) and len(maps) >= len(names):
                    for i, name in enumerate(names):
                        if i < len(maps):
                            metrics_dict[f'metrics/{name}/mAP50-95'] = float(maps[i])
            if hasattr(box, 'maps50'):
                maps50 = box.maps50  # mAP50 per class
                if isinstance(maps50, (list, np.ndarray)) and len(maps50) >= len(names):
                    for i, name in enumerate(names):
                        if i < len(maps50):
                            metrics_dict[f'metrics/{name}/mAP50'] = float(maps50[i])
        
        # Th·ª≠ l·∫•y t·ª´ dict n·∫øu c√≥
        if not metrics_dict and isinstance(results, dict):
            metrics_dict = results
        
        # In th√¥ng tin debug n·∫øu kh√¥ng t√¨m th·∫•y metrics
        if not metrics_dict:
            print("‚ö†Ô∏è  Kh√¥ng th·ªÉ tr√≠ch xu·∫•t metrics t·ª± ƒë·ªông. K·∫øt qu·∫£ c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c runs.")
            print(f"   Ki·ªÉm tra th∆∞ m·ª•c: {os.path.join(args.out_dir, 'runs')}")
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi tr√≠ch xu·∫•t metrics: {e}")
        print("   K·∫øt qu·∫£ validation ƒë√£ ƒë∆∞·ª£c ch·∫°y, ki·ªÉm tra th∆∞ m·ª•c runs ƒë·ªÉ xem chi ti·∫øt.")
    
    # In k·∫øt qu·∫£
    print(format_metrics(metrics_dict))
    
    # L∆∞u JSON n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
    if args.save_json:
        json_path = os.path.join(args.out_dir, f"metrics_{args.split}.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(metrics_dict, f, indent=2)
        print(f"\nüíæ Metrics ƒë√£ l∆∞u v√†o: {json_path}")
    
    # ================================================================
    # B∆Ø·ªöC 5 - VISUALIZATION (t√πy ch·ªçn)
    # ================================================================
    if args.save_vis:
        print("\nüé® ƒêang t·∫°o visualization (GT + Predicted boxes)...")
        vis_dir = args.vis_dir or os.path.join(args.out_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        # T√¨m th∆∞ m·ª•c labels t∆∞∆°ng ·ª©ng v·ªõi img_dir
        if args.label_dir:
            label_dir = args.label_dir
        else:
            # T·ª± ƒë·ªông t√¨m: gi·∫£ ƒë·ªãnh labels ·ªü c√πng parent directory, thay '/images' -> '/labels'
            label_dir = args.img_dir.replace("/images", "/labels").replace("\\images", "\\labels")
            if not os.path.exists(label_dir):
                # Th·ª≠ t√¨m labels ·ªü processed/knee/labels
                if "knee" in args.img_dir:
                    label_dir = os.path.join(os.path.dirname(os.path.dirname(args.img_dir)), "knee", "labels")
                else:
                    label_dir = os.path.join(os.path.dirname(args.img_dir), "labels")
        
        if not os.path.exists(label_dir):
            print(f"  ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c labels: {label_dir}")
            print(f"  Ch·ªâ v·∫Ω predicted boxes (kh√¥ng c√≥ GT)...")
            label_dir = None
        
        # ƒê·ªçc danh s√°ch ·∫£nh t·ª´ split
        split_txt = os.path.join(args.out_dir, f"{args.split}.txt")
        with open(split_txt, "r", encoding="utf-8") as f:
            image_paths = [line.strip() for line in f if line.strip()]
        
        # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng ·∫£nh
        if args.vis_n > 0:
            image_paths = image_paths[:args.vis_n]
        
        print(f"  Visualizing {len(image_paths)} images...")
        if label_dir:
            print(f"  Label directory: {label_dir}")
        print(f"  GT boxes: m√†u xanh l√°")
        print(f"  Predicted boxes: m√†u ƒë·ªè")
        
        success_count = 0
        for img_path in image_paths:
            # T√¨m file label t∆∞∆°ng ·ª©ng
            img_name = os.path.splitext(os.path.basename(img_path))[0]
            label_path = None
            if label_dir:
                label_path = os.path.join(label_dir, f"{img_name}.txt")
            
            # ƒê∆∞·ªùng d·∫´n output
            out_filename = f"{img_name}_vis.jpg"
            out_path = os.path.join(vis_dir, out_filename)
            
            # V·∫Ω c·∫£ GT v√† predicted boxes
            if visualize_predictions_with_gt(
                img_path=img_path,
                label_path=label_path or "",
                detector=detector,
                conf_threshold=args.conf,
                iou_threshold=args.iou,
                imgsz=args.imgsz,
                device=device_arg,
                out_path=out_path,
            ):
                success_count += 1
        
        print(f"‚úÖ ƒê√£ t·∫°o visualization cho {success_count}/{len(image_paths)} ·∫£nh")
        print(f"   L∆∞u t·∫°i: {vis_dir}")
    
    print(f"\n{'='*60}\n")
    print("‚ú® Ho√†n t·∫•t ƒë√°nh gi√°!")


if __name__ == "__main__":
    main()

