import os
import cv2
import albumentations as A
from tqdm import tqdm
from dataset import YoloDataset
from albumentations.pytorch.transforms import ToTensorV2


def check_augmentation(dataset, num_trials=3):
    """
    Ki·ªÉm tra to√†n b·ªô dataset qua augment xem c√≥ l·ªói g√¨ kh√¥ng.
    - num_trials: s·ªë l·∫ßn th·ª≠ augment m·ªói ·∫£nh (ƒë·ªÉ random nhi·ªÅu bi·∫øn th·ªÉ)
    """
    total_images = len(dataset)
    total_boxes = 0
    total_aug_boxes = 0
    errors = []
    empty_after_aug = 0

    print(f"üîç Checking {total_images} images √ó {num_trials} augmentations...")

    for i in tqdm(range(total_images)):
        img_name = dataset.image_files[i]
        try:
            image = cv2.imread(os.path.join(dataset.img_dir, img_name))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            h, w, _ = image.shape

            # ƒë·ªçc bbox g·ªëc
            label_path = os.path.join(
                dataset.label_dir, os.path.splitext(img_name)[0] + ".txt"
            )
            boxes = []
            labels = []
            if os.path.exists(label_path):
                with open(label_path, "r") as f:
                    for line in f.readlines():
                        c, x, y, bw, bh = map(float, line.strip().split())
                        x1 = (x - bw / 2) * w
                        y1 = (y - bh / 2) * h
                        x2 = (x + bw / 2) * w
                        y2 = (y + bh / 2) * h
                        boxes.append([x1, y1, x2, y2])
                        labels.append(int(c))
            total_boxes += len(boxes)

            # th·ª≠ augment nhi·ªÅu l·∫ßn
            for _ in range(num_trials):
                try:
                    transformed = dataset.transform(
                        image=image, bboxes=boxes, class_labels=labels
                    )
                    aug_boxes = transformed["bboxes"]
                    total_aug_boxes += len(aug_boxes)

                    # ki·ªÉm tra box c√≤n n·∫±m trong ·∫£nh
                    for x1, y1, x2, y2 in aug_boxes:
                        if not (0 <= x1 < x2 <= w and 0 <= y1 < y2 <= h):
                            errors.append(
                                f"{img_name}: out-of-bound box ({x1:.1f},{y1:.1f},{x2:.1f},{y2:.1f})"
                            )

                    # ki·ªÉm tra m·∫•t box
                    if len(aug_boxes) == 0 and len(boxes) > 0:
                        empty_after_aug += 1

                except Exception as e:
                    errors.append(f"{img_name}: augmentation error ‚Üí {str(e)}")

        except Exception as e:
            errors.append(f"{img_name}: load error ‚Üí {str(e)}")

    # th·ªëng k√™
    print("\n===== SUMMARY =====")
    print(f"Total images: {total_images}")
    print(f"Total original boxes: {total_boxes}")
    print(f"Total aug boxes (all trials): {total_aug_boxes}")
    print(f"Images with empty boxes after aug: {empty_after_aug}")
    print(f"Errors detected: {len(errors)}")

    if errors:
        print("\nSome examples of errors:")
        for e in errors[:10]:
            print(" -", e)
        with open("augmentation_errors.log", "w", encoding="utf-8") as f:
            f.write("\n".join(errors))
        print("\n‚ö†Ô∏è Full log saved to: augmentation_errors.log")
    else:
        print("‚úÖ No errors detected. All augmentations are valid!")


if __name__ == "__main__":
    image_size = 512
    # ƒê·ªãnh nghƒ©a augment gi·ªëng khi train
    # Kh√¥ng d√πng - kh√¥ng ph√π h·ª£p ·∫£nh y t·∫ø A.Rotate(limit=20, p=1),

    transform = transform = A.Compose(
        [
            A.Resize(image_size, image_size, interpolation=cv2.INTER_LINEAR),
            A.HorizontalFlip(p=0.5),
            A.ShiftScaleRotate(
                shift_limit=0.02,
                scale_limit=0.05,
                rotate_limit=5,
                border_mode=cv2.BORDER_CONSTANT,
                value=0,
                p=0.7,
            ),
            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
            A.RandomBrightnessContrast(
                brightness_limit=0.1, contrast_limit=0.15, p=0.5
            ),
            A.GaussNoise(var_limit=(5, 15), p=0.2),
            A.MotionBlur(blur_limit=3, p=0.2),
            A.Normalize(mean=[0.485], std=[0.229]),
            ToTensorV2(),
        ],
        bbox_params=A.BboxParams(
            format="pascal_voc",
            label_fields=["class_labels"],
            min_visibility=0.01,
            clip=True,  # auto clamp v·ªÅ bi√™n ·∫£nh
            check_each_transform=False,  # b·ªè ki·ªÉm tra nghi√™m ng·∫∑t m·ªói b∆∞·ªõc
        ),
    )
    dataset = YoloDataset(
        img_dir="dataset/images", label_dir="dataset/labels", transform=transform
    )

    check_augmentation(dataset, num_trials=3)
